{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81173011-b9be-4aae-8765-0052b7c564e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# IMPROVED SYNTHETIC DATA WITH TRUE SIGNAL + HIGH ACCURACY MODEL\n",
    "# ===============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================================================\n",
    "# 1. REALISTIC SYNTHETIC FINANCIAL DATA GENERATION\n",
    "# ===============================================================\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 3000\n",
    "dates = pd.date_range(start=\"2012-01-01\", periods=N, freq=\"D\")\n",
    "\n",
    "# Base price series (random walk)\n",
    "price = 100 + np.cumsum(np.random.normal(0, 0.8, N))\n",
    "\n",
    "# Momentum\n",
    "momentum_5 = price - pd.Series(price).shift(5)\n",
    "momentum_10 = price - pd.Series(price).shift(10)\n",
    "\n",
    "# Volatility\n",
    "volatility = np.abs(np.random.normal(1.5, 0.4, N))\n",
    "\n",
    "# Sentiment (strong predictor)\n",
    "sentiment = np.random.normal(0, 1, N)\n",
    "\n",
    "# Yield curve (macro signal)\n",
    "yield_spread = np.random.normal(1.5, 0.2, N)\n",
    "\n",
    "# Inflation (inverse effect)\n",
    "inflation = np.random.normal(5, 0.3, N)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"date\": dates,\n",
    "    \"close_price\": price,\n",
    "    \"momentum_5\": momentum_5,\n",
    "    \"momentum_10\": momentum_10,\n",
    "    \"volatility\": volatility,\n",
    "    \"sentiment\": sentiment,\n",
    "    \"yield_spread\": yield_spread,\n",
    "    \"inflation\": inflation,\n",
    "})\n",
    "\n",
    "# ===============================================================\n",
    "# 2. CREATE TRUE SIGNAL FOR FUTURE RETURNS\n",
    "# ===============================================================\n",
    "\n",
    "# \"True\" underlying formula (hidden from model)\n",
    "true_signal = (\n",
    "    0.6 * np.sign(momentum_10) +\n",
    "    0.4 * np.sign(momentum_5) +\n",
    "    0.8 * np.sign(sentiment) -\n",
    "    0.7 * np.sign(volatility - volatility.mean()) +\n",
    "    0.5 * np.sign(yield_spread - yield_spread.mean()) -\n",
    "    0.3 * np.sign(inflation - inflation.mean())\n",
    ")\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.normal(0, 0.7, N)\n",
    "direction = (true_signal + noise > 0).astype(int)\n",
    "\n",
    "df[\"target\"] = direction\n",
    "df = df.dropna()\n",
    "\n",
    "# ===============================================================\n",
    "# 3. TRAIN TEST SPLIT\n",
    "# ===============================================================\n",
    "\n",
    "features = [\"momentum_5\",\"momentum_10\",\"volatility\",\"sentiment\",\"yield_spread\",\"inflation\"]\n",
    "X = df[features]\n",
    "y = df[\"target\"]\n",
    "\n",
    "split = int(0.8 * len(df))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ===============================================================\n",
    "# 4. HIGH ACCURACY MODEL â€” XGBOOST\n",
    "# ===============================================================\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ===============================================================\n",
    "# 5. PERFORMANCE\n",
    "# ===============================================================\n",
    "\n",
    "preds = (model.predict_proba(X_test)[:, 1] > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds))\n",
    "\n",
    "# ===============================================================\n",
    "# 6. SHAP INTERPRETATION\n",
    "# ===============================================================\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_vals = explainer.shap_values(X_train)\n",
    "\n",
    "shap.summary_plot(shap_vals, X_train, features)\n",
    "shap.summary_plot(shap_vals, X_train, features, plot_type=\"bar\")\n",
    "\n",
    "# ===============================================================\n",
    "# 7. LIME LOCAL EXPLANATION\n",
    "# ===============================================================\n",
    "\n",
    "lime_exp = LimeTabularExplainer(\n",
    "    X_train,\n",
    "    feature_names=features,\n",
    "    class_names=[\"Down\", \"Up\"],\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "instance = X_test[10]\n",
    "lime_ex = lime_exp.explain_instance(instance, model.predict_proba, num_features=6)\n",
    "\n",
    "print(\"\\nLIME Explanation:\")\n",
    "print(lime_ex.as_list())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
